{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ab33e3d",
   "metadata": {},
   "source": [
    "🔑 Common Terms in ML & Data Preprocessing\n",
    "1. Continuous Values\n",
    "\n",
    "Numbers that can take any value within a range.\n",
    "\n",
    "Example: Sales = 123.45 or Temperature = 28.3°C.\n",
    "\n",
    "Often need scaling before ML.\n",
    "\n",
    "2. Discrete Values\n",
    "\n",
    "Numbers or categories that are countable and separate (no fractions).\n",
    "\n",
    "Example: Number of Orders = 5, or Category = Furniture.\n",
    "\n",
    "Usually treated as categorical features.\n",
    "\n",
    "3. Categorical Variables\n",
    "\n",
    "Data stored as labels or groups instead of numbers.\n",
    "\n",
    "Example: Segment = [Consumer, Corporate, Home Office].\n",
    "\n",
    "Need encoding (One-Hot Encoding, Label Encoding) before ML.\n",
    "\n",
    "4. On the Same Scale\n",
    "\n",
    "When features are in a comparable numeric range.\n",
    "\n",
    "Example:\n",
    "\n",
    "Feature A = \"Age\" (20–70)\n",
    "\n",
    "Feature B = \"Income\" (10,000–1,000,000)\n",
    "\n",
    "Without scaling, the algorithm will think Income is more important just because it has bigger numbers.\n",
    "\n",
    "Scaling makes them fairly comparable.\n",
    "\n",
    "5. Normalization (Min-Max Scaling)\n",
    "\n",
    "Rescales values into 0 to 1 range.\n",
    "\n",
    "Formula:\n",
    "\n",
    "𝑥\n",
    "′\n",
    "=\n",
    "𝑥\n",
    "−\n",
    "min\n",
    "(\n",
    "𝑥\n",
    ")\n",
    "max\n",
    "(\n",
    "𝑥\n",
    ")\n",
    "−\n",
    "min\n",
    "(\n",
    "𝑥\n",
    ")\n",
    "x\n",
    "′\n",
    "=\n",
    "max(x)−min(x)\n",
    "x−min(x)\n",
    "\t​\n",
    "\n",
    "\n",
    "Example: If Sales = 500, min=0, max=1000 → normalized value = 0.5.\n",
    "\n",
    "6. Standardization (Z-score Scaling)\n",
    "\n",
    "Converts data to have mean = 0, standard deviation = 1.\n",
    "\n",
    "Formula:\n",
    "\n",
    "𝑧\n",
    "=\n",
    "𝑥\n",
    "−\n",
    "𝜇\n",
    "𝜎\n",
    "z=\n",
    "σ\n",
    "x−μ\n",
    "\t​\n",
    "\n",
    "\n",
    "where μ = mean, σ = standard deviation.\n",
    "\n",
    "Example: If Sales = 500, mean=300, std=100 → z-score = (500-300)/100 = 2.0.\n",
    "\n",
    "Interpretation: \"Sales is 2 standard deviations above the mean.\"\n",
    "\n",
    "7. Z-score\n",
    "\n",
    "A standardized score showing how far a value is from the mean in terms of standard deviations.\n",
    "\n",
    "Example: z=0 → exactly the mean; z=+2 → much higher; z=-1 → below average.\n",
    "\n",
    "8. Outlier\n",
    "\n",
    "A data point that is very different from the majority.\n",
    "\n",
    "Example: In Sales, most values < 5000, but one is 50,000 → outlier.\n",
    "\n",
    "Important to detect because it can skew models.\n",
    "\n",
    "9. Feature Engineering\n",
    "\n",
    "The process of transforming raw data into meaningful inputs for ML.\n",
    "\n",
    "Includes binning, scaling, encoding, creating new features (like Profit Margin = Sales - Cost).\n",
    "\n",
    "10. Target Variable (y)\n",
    "\n",
    "The outcome you’re predicting.\n",
    "\n",
    "Example: Predicting Sales (regression) or Segment (classification).\n",
    "\n",
    "11. Feature / Independent Variable (X)\n",
    "\n",
    "The input(s) used to predict the target.\n",
    "\n",
    "Example: Customer Age, Region, Category → help predict Sales.\n",
    "\n",
    "12. Overfitting\n",
    "\n",
    "When a model memorizes training data instead of generalizing.\n",
    "\n",
    "Good performance on training, bad on test data.\n",
    "\n",
    "13. Underfitting\n",
    "\n",
    "When a model is too simple and can’t capture patterns.\n",
    "\n",
    "Bad on both training and test data.\n",
    "\n",
    "14. Bias vs Variance\n",
    "\n",
    "Bias: Error from making the model too simple (underfitting).\n",
    "\n",
    "Variance: Error from making the model too sensitive to noise (overfitting).\n",
    "\n",
    "Goal = balance (Bias-Variance Tradeoff).\n",
    "\n",
    "15. Training vs Testing Data\n",
    "\n",
    "Training data: Used to build the model.\n",
    "\n",
    "Testing data: Used to check how well it works on unseen data.\n",
    "\n",
    "Often split 70% train, 30% test (or similar)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e1ba91",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
